{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as nd\n",
    "from tld import get_tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load movie dataset\n",
    "df_emacs = pd.read_csv('C:\\\\reddit\\\\df_emacs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load music dataset\n",
    "df_vim = pd.read_csv('C:\\\\reddit\\\\df_vim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data \n",
    "#url maniupuation to find the domain \n",
    "#time converter to the human readable format\n",
    "#change the score and comment_number and award from string to numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url extraction to find domain  \n",
    "def url_fixer(dataset):\n",
    "    list_of_url_names = dataset['url'].to_list()\n",
    "    domain_list = []\n",
    "    for i in list_of_url_names:\n",
    "        if (i.find('.com') != -1 or i.find('.org') != -1 or i.find('.edu') != -1 or i.find('.net') != -1 ): \n",
    "            info = get_tld(i, as_object=True)\n",
    "            domain = info.fld\n",
    "            domain_list.append(domain) \n",
    "        else :\n",
    "            domain_list.append('reddit.com') \n",
    "    dataset['url'] = pd.Series(domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fixer(df_vim)\n",
    "url_fixer(df_emacs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert time from unix time to readable date time\n",
    "df_vim['created'] = pd.to_datetime(df_vim['created'], unit='s')\n",
    "df_emacs['created'] = pd.to_datetime(df_emacs['created'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_int(dataset):\n",
    "    dataset[\"score\"] = pd.to_numeric(dataset[\"score\"])\n",
    "    dataset[\"comments_number\"] = pd.to_numeric(dataset[\"comments_number\"])\n",
    "    dataset[\"award\"] = pd.to_numeric(dataset[\"award\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_int(df_emacs)\n",
    "str_int(df_vim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"C://reddit\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vim.to_csv (r'C:/reddit/clean_df_vim.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emacs.to_csv (r'C:/reddit/clean_df_emacs.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
